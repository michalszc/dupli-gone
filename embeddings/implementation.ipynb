{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87772ee3",
   "metadata": {},
   "source": [
    "# Efficient Duplicate Detection with Embeddings and FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6a4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalszczygiel/workspace/dupli-gone/embeddings/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import List, Any, Dict\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a80e531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xml_from_url(url: str) -> pd.DataFrame:\n",
    "    r = requests.get(url)\n",
    "\n",
    "    root = ET.fromstring(r.text)\n",
    "    records = root.find('records') \n",
    "\n",
    "    def extract(child):\n",
    "        parts = []\n",
    "        for sub in child:\n",
    "            if len(sub) != 0:\n",
    "                parts.append(extract(sub))\n",
    "                continue\n",
    "\n",
    "            if sub.tag.lower() in ('_face','_font','_size'):\n",
    "                continue\n",
    "\n",
    "            if sub.text and sub.text.strip():\n",
    "                parts.append(sub.text.strip())\n",
    "        text = ','.join(parts)\n",
    "\n",
    "        return text\n",
    "\n",
    "    rows = []\n",
    "    for rec in records.findall('record'):\n",
    "        row = {}\n",
    "        for child in rec:\n",
    "            text = ''\n",
    "            tag = child.tag\n",
    "            if len(child) == 0:\n",
    "                text = (child.text or '').strip()\n",
    "            else:\n",
    "                text = extract(child)\n",
    "\n",
    "            row[tag] = text\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97d30728",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Benchmark:\n",
    "    '''\n",
    "    A class for benchmarking classification models.\n",
    "\n",
    "    Args:\n",
    "        model (Any): A model object that has a `predict` method.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: Any, average: str = 'binary'):\n",
    "        self.model = model\n",
    "        self.average = average\n",
    "\n",
    "    def evaluate(self, X, y_true) -> Dict[str, float]:\n",
    "        '''\n",
    "        Calculates classification metrics and prediction time.\n",
    "\n",
    "        Args:\n",
    "            X: Input features.\n",
    "            y_true: True labels.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing metrics and prediction time.\n",
    "        '''\n",
    "        start_time = time.time()\n",
    "        y_pred = self.model.predict(X)\n",
    "        end_time = time.time()\n",
    "\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred, average='binary', zero_division=0),\n",
    "            'recall': recall_score(y_true, y_pred, average='binary', zero_division=0),\n",
    "            'f1': f1_score(y_true, y_pred, average='binary', zero_division=0),\n",
    "            'prediction_time_sec': end_time - start_time,\n",
    "            'number_of_samples': len(y_true),\n",
    "        }\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class EmbeddingDeduplicator:\n",
    "    '''\n",
    "    A class to deduplicate text embeddings using FAISS.\n",
    "    '''\n",
    "    def __init__(self, model_name: str = 'sentence-transformers/all-MiniLM-L6-v2', dimension: int = 384, top_k: int = 5, threshold: float = 0.85):\n",
    "        self.model = SentenceTransformer(model_name, cache_folder='.cache')\n",
    "        self.index = faiss.IndexFlatIP(dimension)\n",
    "        self.top_k = top_k\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def predict(self, texts: List[str]) -> List[int]:\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=False, normalize_embeddings=True)\n",
    "        self.index.add(embeddings)\n",
    "\n",
    "        similarities, neighbors = self.index.search(embeddings, self.top_k)\n",
    "\n",
    "        duplicates = set()\n",
    "\n",
    "        for i in range(len(texts)):\n",
    "            for j, sim in zip(neighbors[i][1:], similarities[i][1:]):\n",
    "                if sim > self.threshold:\n",
    "                        duplicates.add(i)\n",
    "                        duplicates.add(j)\n",
    "\n",
    "        indices = np.zeros(len(texts), dtype=int)\n",
    "        indices[list(duplicates)] = 1\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5615e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/IEBH/dedupe-sweep/master/test/data/tafenoquine.xml'\n",
    "\n",
    "df_tafenoquine = load_xml_from_url(url)\n",
    "df_tafenoquine['label'] = df_tafenoquine['caption'].apply(lambda x: 1 if x == 'Duplicate' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f42282f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9553072625698324,\n",
       " 'precision': 0.9344262295081968,\n",
       " 'recall': 1.0,\n",
       " 'f1': 0.9661016949152542,\n",
       " 'prediction_time_sec': 0.5236790180206299,\n",
       " 'number_of_samples': 179}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduplicator = EmbeddingDeduplicator(threshold=0.95, top_k=3)\n",
    "benchmark = Benchmark(deduplicator)\n",
    "benchmark.evaluate(df_tafenoquine['abstract'].to_list(), df_tafenoquine['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9ae6e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/IEBH/dedupe-sweep/master/test/data/uti.xml'\n",
    "\n",
    "df_uti = load_xml_from_url(url)\n",
    "df_uti['label'] = df_uti['caption'].apply(lambda x: 1 if x == 'Duplicate' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb568b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9463087248322147,\n",
       " 'precision': 0.9257425742574258,\n",
       " 'recall': 0.935,\n",
       " 'f1': 0.9303482587064676,\n",
       " 'prediction_time_sec': 2.4804320335388184,\n",
       " 'number_of_samples': 1043}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduplicator = EmbeddingDeduplicator(threshold=0.95, top_k=3)\n",
    "benchmark = Benchmark(deduplicator)\n",
    "benchmark.evaluate(df_uti['abstract'].to_list(), df_uti['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8f3a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/IEBH/dedupe-sweep/master/test/data/diabetes.xml'\n",
    "\n",
    "df_diabetes = load_xml_from_url(url)\n",
    "df_diabetes['label'] = df_diabetes['caption'].apply(lambda x: 1 if x == 'Duplicate' else 0)\n",
    "df_diabetes = df_diabetes.dropna(subset=['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "346b966f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9418383749817332,\n",
       " 'precision': 0.9681689253072802,\n",
       " 'recall': 0.9118432769367765,\n",
       " 'f1': 0.9391623356771629,\n",
       " 'prediction_time_sec': 16.29113507270813,\n",
       " 'number_of_samples': 6843}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduplicator = EmbeddingDeduplicator(threshold=0.95, top_k=3)\n",
    "benchmark = Benchmark(deduplicator)\n",
    "benchmark.evaluate(df_diabetes['abstract'].to_list(), df_diabetes['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8b2aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/IEBH/dedupe-sweep/master/test/data/copper.xml'\n",
    "\n",
    "df_copper = load_xml_from_url(url)\n",
    "df_copper['label'] = df_copper['caption'].apply(lambda x: 1 if x == 'Duplicate' else 0)\n",
    "df_copper = df_copper.dropna(subset=['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "175dd6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9859437751004017,\n",
       " 'precision': 0.9755244755244755,\n",
       " 'recall': 1.0,\n",
       " 'f1': 0.9876106194690265,\n",
       " 'prediction_time_sec': 1.1990149021148682,\n",
       " 'number_of_samples': 498}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduplicator = EmbeddingDeduplicator(threshold=0.95, top_k=3)\n",
    "benchmark = Benchmark(deduplicator)\n",
    "benchmark.evaluate(df_copper['abstract'].to_list(), df_copper['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85ff47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/IEBH/dedupe-sweep/master/test/data/blue-light.xml'\n",
    "\n",
    "df_blue_light = load_xml_from_url(url)\n",
    "df_blue_light['label'] = df_blue_light['caption'].apply(lambda x: 1 if x == 'Duplicate' else 0)\n",
    "df_blue_light = df_blue_light.dropna(subset=['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f49464fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9392059553349876,\n",
       " 'precision': 0.9814385150812065,\n",
       " 'recall': 0.9116379310344828,\n",
       " 'f1': 0.9452513966480447,\n",
       " 'prediction_time_sec': 1.8415331840515137,\n",
       " 'number_of_samples': 806}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduplicator = EmbeddingDeduplicator(threshold=0.95, top_k=3)\n",
    "benchmark = Benchmark(deduplicator)\n",
    "benchmark.evaluate(df_blue_light['abstract'].to_list(), df_blue_light['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
