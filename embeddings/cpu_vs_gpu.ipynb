{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install faiss-gpu-cu12","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:44:00.487506Z","iopub.execute_input":"2025-05-22T19:44:00.487858Z","iopub.status.idle":"2025-05-22T19:44:05.932553Z","shell.execute_reply.started":"2025-05-22T19:44:00.487833Z","shell.execute_reply":"2025-05-22T19:44:05.931645Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-gpu-cu12\n  Downloading faiss_gpu_cu12-1.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (25.0)\nRequirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (12.4.127)\nRequirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (12.9.0.13)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2->faiss-gpu-cu12) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2->faiss-gpu-cu12) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2->faiss-gpu-cu12) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2->faiss-gpu-cu12) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2->faiss-gpu-cu12) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2->faiss-gpu-cu12) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2->faiss-gpu-cu12) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2->faiss-gpu-cu12) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2->faiss-gpu-cu12) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2->faiss-gpu-cu12) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2->faiss-gpu-cu12) (2024.2.0)\nDownloading faiss_gpu_cu12-1.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu-cu12\nSuccessfully installed faiss-gpu-cu12-1.11.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from typing import List\nimport numpy as np\nimport faiss\nfrom sentence_transformers import SentenceTransformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:44:05.934189Z","iopub.execute_input":"2025-05-22T19:44:05.934432Z","iopub.status.idle":"2025-05-22T19:44:32.368678Z","shell.execute_reply.started":"2025-05-22T19:44:05.934404Z","shell.execute_reply":"2025-05-22T19:44:32.367917Z"}},"outputs":[{"name":"stderr","text":"2025-05-22 19:44:18.714620: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747943058.887765      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747943058.941416      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# dataset.py\nimport requests\nimport xml.etree.ElementTree as ET\nimport pandas as pd\nfrom tqdm import tqdm\n\nDATASETS = [\n    'tafenoquine',\n    'uti',\n    'diabetes',\n    'copper',\n    'blue-light',\n]\n\nBASE_URL = 'https://raw.githubusercontent.com/IEBH/dedupe-sweep/master/test/data/'\n\ndef load_xml_from_url(url: str) -> pd.DataFrame:\n    '''\n    Load XML data from a URL and convert it to a pandas DataFrame.\n    '''\n    r = requests.get(url)\n\n    root = ET.fromstring(r.text)\n    records = root.find('records') \n\n    def extract(child):\n        parts = []\n        for sub in child:\n            if len(sub) != 0:\n                parts.append(extract(sub))\n                continue\n\n            if sub.tag.lower() in ('_face','_font','_size'):\n                continue\n\n            if sub.text and sub.text.strip():\n                parts.append(sub.text.strip())\n        text = ','.join(parts)\n\n        return text\n\n    rows = []\n    for rec in records.findall('record'):\n        row = {}\n        for child in rec:\n            text = ''\n            tag = child.tag\n            if len(child) == 0:\n                text = (child.text or '').strip()\n            else:\n                text = extract(child)\n\n            row[tag] = text\n        rows.append(row)\n\n    return pd.DataFrame(rows)\n\ndef prepare_dataset() -> pd.DataFrame:\n    '''\n    Load and prepare the dataset for training and evaluation.\n    '''\n    dfs = [\n        load_xml_from_url(f'{BASE_URL}{dataset}.xml')\n        for dataset in tqdm(DATASETS, desc=\"Loading datasets\")\n    ]\n    df = pd.concat(dfs, ignore_index=True)\n    df['label'] = df['caption'].apply(lambda x: 1 if x == 'Duplicate' else 0)\n    df.dropna(subset=['abstract'], inplace=True)\n\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:44:32.369608Z","iopub.execute_input":"2025-05-22T19:44:32.370071Z","iopub.status.idle":"2025-05-22T19:44:32.378104Z","shell.execute_reply.started":"2025-05-22T19:44:32.370044Z","shell.execute_reply":"2025-05-22T19:44:32.377380Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# benchmark.py\nimport time\nfrom typing import Any, Dict, List\n\nimport numpy as np\nfrom sklearn.utils.class_weight import compute_sample_weight\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nclass Benchmark:\n    '''\n    A class for benchmarking classification models.\n\n    Args:\n        model (Any): A model object that has a `predict` method.\n    '''\n\n    def __init__(self, model: Any):\n        self.model = model\n\n    def evaluate(self, X: List[str], y_true: np.ndarray, verbose: bool = False) -> Dict[str, float]:\n        '''\n        Calculates classification metrics and prediction time.\n\n        Args:\n            X: Input features.\n            y_true: True labels.\n            verbose: If True, prints the summary of metrics.\n\n        Returns:\n            dict: A dictionary containing metrics and prediction time.\n        '''\n        start_time = time.time()\n        y_pred = self.model.predict(X)\n        end_time = time.time()\n\n        sample_weights = compute_sample_weight(class_weight='balanced', y=y_true)\n\n        metrics = {\n            'accuracy': accuracy_score(y_true, y_pred, sample_weight=sample_weights),\n            'precision': precision_score(y_true, y_pred, average='binary', zero_division=0, sample_weight=sample_weights),\n            'recall': recall_score(y_true, y_pred, average='binary', zero_division=0, sample_weight=sample_weights),\n            'f1': f1_score(y_true, y_pred, average='binary', zero_division=0, sample_weight=sample_weights),\n            'prediction_time_sec': end_time - start_time,\n            'samples': len(y_true),\n            'duplicates': sum(y_true),\n        }\n\n        if verbose:\n            print('Summary:')\n            print(f\"{'Metric':<20}{'Value':>15}\")\n            print('-' * 35)\n            for metric, value in metrics.items():\n                print(f'{metric.capitalize():<20}{value:>15.5f}')\n\n        return metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:44:32.380109Z","iopub.execute_input":"2025-05-22T19:44:32.380381Z","iopub.status.idle":"2025-05-22T19:44:32.594748Z","shell.execute_reply.started":"2025-05-22T19:44:32.380358Z","shell.execute_reply":"2025-05-22T19:44:32.594058Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df = prepare_dataset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:44:32.595637Z","iopub.execute_input":"2025-05-22T19:44:32.595899Z","iopub.status.idle":"2025-05-22T19:44:38.137184Z","shell.execute_reply.started":"2025-05-22T19:44:32.595878Z","shell.execute_reply":"2025-05-22T19:44:38.136561Z"}},"outputs":[{"name":"stderr","text":"Loading datasets: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"texts = df['abstract'].to_list()\nlabels = df['label'].to_list()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:44:38.137832Z","iopub.execute_input":"2025-05-22T19:44:38.138096Z","iopub.status.idle":"2025-05-22T19:44:38.141894Z","shell.execute_reply.started":"2025-05-22T19:44:38.138076Z","shell.execute_reply":"2025-05-22T19:44:38.141331Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class EmbeddingDeduplicatorCPU:\n    '''\n    A class to deduplicate text embeddings using FAISS.\n    '''\n    def __init__(self, model_name: str = 'sentence-transformers/all-MiniLM-L6-v2', dimension: int = 384, top_k: int = 3, threshold: float = 0.85, bacth_size: int = 32):\n        self.model = SentenceTransformer(model_name, cache_folder='.cache')\n        self.dimension = dimension\n        self.top_k = top_k\n        self.threshold = threshold\n        self.batch_size = bacth_size\n    \n    def predict(self, texts: List[str]) -> np.ndarray:\n        embeddings = self.model.encode(texts, show_progress_bar=False, normalize_embeddings=True, batch_size=self.batch_size)\n        \n        index = faiss.IndexFlatIP(self.dimension)\n        index.add(embeddings)\n\n        similarities, neighbors = index.search(embeddings, self.top_k)\n\n        duplicates = set()\n\n        for i in range(len(texts)):\n            for j, sim in zip(neighbors[i][1:], similarities[i][1:]):\n                if sim > self.threshold:\n                        duplicates.add(i)\n                        duplicates.add(j)\n\n        indices = np.zeros(len(texts), dtype=int)\n        indices[list(duplicates)] = 1\n        return indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:44:38.142535Z","iopub.execute_input":"2025-05-22T19:44:38.142780Z","iopub.status.idle":"2025-05-22T19:44:38.153468Z","shell.execute_reply.started":"2025-05-22T19:44:38.142758Z","shell.execute_reply":"2025-05-22T19:44:38.152798Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"deduplicator = EmbeddingDeduplicatorCPU(\n    model_name='sentence-transformers/paraphrase-MiniLM-L3-v2',\n    dimension=384,\n    threshold=0.96,\n    top_k=3,\n    bacth_size=256\n)\nbenchmark = Benchmark(deduplicator)\nmetrics = benchmark.evaluate(texts, labels, verbose=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:44:38.154063Z","iopub.execute_input":"2025-05-22T19:44:38.154492Z","iopub.status.idle":"2025-05-22T19:44:56.878829Z","shell.execute_reply.started":"2025-05-22T19:44:38.154469Z","shell.execute_reply":"2025-05-22T19:44:56.878151Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8e9564dbe0e4090bc1f8b7809537b06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3470e2541a774b619eaa00e14176324d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.83k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1173613490794729aa3e6f194e007206"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab0eb442fc1c48a8b545bad91ef9a93e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c392527c32c24c17b57f296baa956887"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/69.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc2adeb44b18495e8453bc28a7468ca5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25e0548829b1409b9aa3c1c293309c3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4c4cb3770c24cb78845ac42f86ac691"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2795d09150f4b1ca5863ce7599aa6ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"571c6308d023440a8c1b72956b4a689c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a294a635e3444be7afd4266962894b68"}},"metadata":{}},{"name":"stdout","text":"Summary:\nMetric                        Value\n-----------------------------------\nAccuracy                    0.92749\nPrecision                   0.98256\nRecall                      0.87043\nF1                          0.92310\nPrediction_time_sec        10.64631\nSamples                  9347.00000\nDuplicates               4623.00000\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"class EmbeddingDeduplicatorGPU:\n    '''\n    A class to deduplicate text embeddings using FAISS.\n    '''\n    def __init__(self, model_name: str = 'sentence-transformers/all-MiniLM-L6-v2', dimension: int = 384, top_k: int = 3, threshold: float = 0.85, bacth_size: int = 32):\n        self.model = SentenceTransformer(model_name, cache_folder='.cache')\n        self.dimension = dimension\n        self.top_k = top_k\n        self.threshold = threshold\n        self.batch_size = bacth_size\n        self.res = faiss.StandardGpuResources()\n    \n    def predict(self, texts: List[str]) -> np.ndarray:\n        embeddings = self.model.encode(texts, show_progress_bar=False, normalize_embeddings=True, batch_size=self.batch_size)\n        \n        index = faiss.IndexFlatIP(self.dimension)\n        index_gpu = faiss.index_cpu_to_gpu(self.res, 0, index)\n        index_gpu.add(embeddings)\n\n        similarities, neighbors = index_gpu.search(embeddings, self.top_k)\n\n        duplicates = set()\n\n        for i in range(len(texts)):\n            for j, sim in zip(neighbors[i][1:], similarities[i][1:]):\n                if sim > self.threshold:\n                        duplicates.add(i)\n                        duplicates.add(j)\n\n        indices = np.zeros(len(texts), dtype=int)\n        indices[list(duplicates)] = 1\n        return indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:46:23.710347Z","iopub.execute_input":"2025-05-22T19:46:23.711171Z","iopub.status.idle":"2025-05-22T19:46:23.721849Z","shell.execute_reply.started":"2025-05-22T19:46:23.711111Z","shell.execute_reply":"2025-05-22T19:46:23.721004Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"deduplicator = EmbeddingDeduplicatorGPU(\n    model_name='sentence-transformers/paraphrase-MiniLM-L3-v2',\n    dimension=384,\n    threshold=0.96,\n    top_k=3,\n    bacth_size=256\n)\nbenchmark = Benchmark(deduplicator)\nmetrics = benchmark.evaluate(texts, labels, verbose=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:46:26.954756Z","iopub.execute_input":"2025-05-22T19:46:26.955312Z","iopub.status.idle":"2025-05-22T19:46:37.954200Z","shell.execute_reply.started":"2025-05-22T19:46:26.955291Z","shell.execute_reply":"2025-05-22T19:46:37.953239Z"}},"outputs":[{"name":"stdout","text":"Summary:\nMetric                        Value\n-----------------------------------\nAccuracy                    0.92749\nPrecision                   0.98256\nRecall                      0.87043\nF1                          0.92310\nPrediction_time_sec        10.31810\nSamples                  9347.00000\nDuplicates               4623.00000\n","output_type":"stream"}],"execution_count":12}]}